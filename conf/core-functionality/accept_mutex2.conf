#
# 性能测试：
# 
# wrk -t1 -c1 -d5s http://127.0.0.1:8000
# Running 5s test @ http://127.0.0.1:8000
#  1 threads and 1 connections
#  Thread Stats   Avg      Stdev     Max   +/- Stdev
#    Latency    30.58us   26.49us   1.93ms   99.44%
#    Req/Sec    31.10k   590.33    31.77k    82.35%
#  157756 requests in 5.10s, 26.32MB read
# Requests/sec:  30934.85
# Transfer/sec:      5.16MB
#
# 将-c的值调大相当于提高了并发
# 1. c==2, RPS=54.36k, latency=37.05us. 吞吐量提高一倍，延时是微秒级
# 2. c==4, RPS=73.81k, latency=51.95us. 吞吐量提高20k，延时是微秒级
# 3. c==8, RPS=70.95k, latency=127.74us.调大并发后并没有提高吞吐量, 延时翻倍.
# 4. c==32 RPS=76.09k, latency=400.84us. 吞吐量不变，并发提高4倍，延时提高四倍.
# 5. c=128,RPS=79.76k, latency=1.46ms. 吞吐量不变，并发提高4倍，延时提高4倍.
# 综上，吞吐量有一个最大值. 支持的并发数是相对于延时而言的，如果设置的延时为1.46毫秒，则支持128并发.
#
# c==128, 将-t的值调大.
# 1. t==2, RPS=81k, latency=1.55ms
# 2. t==4, RPS=74k, latency=1.53ms
# 3. t==8, RPS=79k, latency=1.59ms
# 综上，增加线程数对系统影响不大
#
# Your goal is to keep the Requests/sec as high as possible and the Latency as low as possible.
#
events {
  accept_mutex off;
}

http {
  server {
    listen 8000;
    location / {
      echo "OK";
    }
  }
}
